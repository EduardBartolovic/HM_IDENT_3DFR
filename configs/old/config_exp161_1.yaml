SEED: 1337  # random seed for reproduce results

RUN_NAME: 'EXP161-rgb_monoffhq-12000T_25P-enc_512-ArcFace-FocalLoss-112_112-batchsize_128-epochs150-IR_50-cleaned'  # experiment_name
DATA_ROOT: '~/dataset7'  # the parent root
TRAIN_SET: 'rgb_monoffhq12000'  # where your train/val/test data are stored

MODEL_ROOT: './model'  # the root to buffer your checkpoints
LOG_ROOT: './log'  # the root to log your train/val status
BACKBONE_RESUME_ROOT: './'  # the root to resume training from a saved checkpoint
HEAD_RESUME_ROOT: './'  # the root to resume training from a saved checkpoint
BACKBONE_NAME: 'IR_50'  # support: ['ResNet_50', 'ResNet_101', 'ResNet_152', 'IR_50', 'IR_101', 'IR_152', 'IR_SE_50', 'IR_SE_101', 'IR_SE_152']
HEAD_NAME: 'ArcFace'  # support:  ['Softmax', 'ArcFace', 'CosFace', 'SphereFace', 'Am_softmax']
LOSS_NAME: 'Focal'  # support: ['Focal', 'Softmax']
DISTANCE_METRIC: 'cosine'  # support: ['euclidean', 'cosine']

INPUT_SIZE: [112, 112]  # support: [112, 112] and [224, 224]
RGB_MEAN: [0.5, 0.5, 0.5]  # for normalize inputs to [-1, 1]
RGB_STD: [0.5, 0.5, 0.5]
EMBEDDING_SIZE: 512  # feature dimension
BATCH_SIZE: 128
DROP_LAST: true  # whether drop the last batch to ensure consistent batch_norm statistics
LR: 0.002  # initial LR
NUM_EPOCH: 150  # total epoch number (use the first 1/25 epochs to warm up)
PATIENCE: 50  # patience for early stopping
WEIGHT_DECAY: 0.0005  # do not apply to batch_norm parameters
MOMENTUM: 0.9
STAGES: [75, 100, 125]  # epoch stages to decay learning rate

MULTI_GPU: false
# flag to use multiple GPUs; if you choose to train with single GPU, you should first run "export CUDA_VISILE_DEVICES=device_id" to specify the GPU card you want to use
GPU_ID: [0]  # specify your GPU ids
PIN_MEMORY: true
NUM_WORKERS: 4